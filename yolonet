import numpy as np
import tensorflow as tf
from tensorflow import keras
from load import DataLoader
import pickle
import random

# alpha = 0.1
# confidence_scale = 7*7*2
size = 448
batch = 5
# offset = np.transpose(np.reshape(np.array([np.arange(7)] * 7 * 2), (2, 7, 7)), (1, 2, 0))



def cal_iou(predict_box, true_box):
    # pre对角坐标
    pre_boxs = tf.stack([predict_box[...,0] - predict_box[...,2]/2.0,
    predict_box[...,1] - predict_box[...,3]/2.0,
    predict_box[...,0] + predict_box[...,2]/2.0,
    predict_box[...,1] + predict_box[...,3]/2.0], axis=-1)
    # label对角坐标
    label_boxs = tf.stack([true_box[...,0] - true_box[...,2]/2.0,
    true_box[...,1] - true_box[...,3]/2.0,
    true_box[...,0] + true_box[...,2]/2.0,
    true_box[...,1] + true_box[...,3]/2.0], axis=-1)
    # cross坐标
    cross_left = tf.maximum(pre_boxs[..., :2], label_boxs[..., :2])
    cross_right = tf.maximum(pre_boxs[..., 2:], label_boxs[..., 2:])

    d = tf.maximum(0.0, cross_right - cross_left)

    s_small = d[..., 0] * d[..., 1]

    s_big = (predict_box[..., 2] * predict_box[..., 3] + true_box[..., 2] * true_box[..., 3]) - s_small
    s_big = tf.maximum(s_big, 0.001)
    iou = tf.clip_by_value(s_small / s_big, 0.0, 1.0)

    # n 7 7 2
    return iou


def loss_function_batch(label, predict):

    label = tf.reshape(label, [batch, 7, 7, 2, 5])
    label = label[:,:,:,0]
    predict_confidence = tf.reshape(predict[:, :7*7*2], [batch, 7, 7, 2])

    predict_box = tf.reshape(predict[:, 7*7*2:], [batch, 7, 7, 2, 4])

    # label 标签 -> [n,7,7,1] [n,7,7,1,4]
    label_confidence = tf.reshape(label[..., 0], [batch, 7, 7, 1])
    label_box = tf.reshape(label[..., 1:5], [batch, 7, 7, 1, 4])

    # 标签边框 -> [n,7,7,2,4] 归一化
    label_box1 = tf.tile(label_box, [1, 1, 1, 2, 1]) / size

    # 变换

    offset = np.transpose(np.reshape(np.array([np.arange(7)] * 7 * 2), (2, 7, 7)), (1, 2, 0))
    set = tf.cast(tf.reshape(tf.constant(offset), [1, 7, 7, 2]), dtype=tf.float32)
    set1 = tf.tile(set, [batch, 1, 1, 1])
    set2 = tf.transpose(set1, (0, 2, 1, 3))
    # print(set1,'set1')
    # print(set2)

    # 预测 x,y相对cell -> 相对全图 [n,7,7,2,4]
    pre_box = tf.stack([(predict_box[..., 0] + set1) / 7.0,
                        (predict_box[..., 1] + set2) / 7.0,
                        tf.square(predict_box[..., 2]),
                        tf.square(predict_box[..., 3])], axis=-1)

    # [n,7,7,2]
    iou = cal_iou(pre_box, label_box1)
    # print(iou.shape, 'iou形状')
    max_iou = tf.reduce_max(iou, 3, keepdims=True)

    # 有目标标记 1*iou
    # [n,7,7,2]
    I_obj = tf.cast((iou >= max_iou), dtype=tf.float32) * label_confidence
    # print(I_obj.shape, 'Iobj形状')
    # 无目标标记 1
    I_nobj = tf.ones_like(I_obj, dtype=tf.float32) - I_obj
    # print(I_nobj.shape, 'nobj')
    # 标签 相对全图 -> 相对cell [n,7,7,2,4]
    label_box1_t = tf.stack([label_box1[..., 0] * 7.0 - set1,
                             label_box1[..., 1] * 7.0 - set2,
                             tf.sqrt(label_box1[..., 2]),
                             tf.sqrt(label_box1[..., 3])], axis=-1)
    # print(label_box1_t.shape, 'label-t')
    # obj_loss

    ob = I_obj * (predict_confidence - iou)
    # print(ob.shape, 'ob')

    obj_loss = tf.reduce_mean(tf.reduce_sum(tf.square(ob), axis=[1, 2, 3]))
    # print(obj_loss, 'objloss')
    # print(obj_loss.shape,'objlossshape')
    # nobj_loss

    nob = I_nobj * predict_confidence
    nobj_loss = tf.reduce_mean(tf.reduce_sum(tf.square(nob), axis=[1, 2, 3]))
    # print(nobj_loss, 'nobjloss')
    # bbox_loss
    # [n,7,7,2,1]
    m = tf.expand_dims(I_obj, 4)
    ob_box = m * (predict_box - label_box1_t)
    bbox_loss = tf.reduce_mean(tf.reduce_sum(tf.square(ob_box), axis=[1,2,3,4])) * 5
    # print(bbox_loss, 'bboxloss')
    # final_loss

    final_loss = obj_loss + nobj_loss + bbox_loss
    # print(final_loss.shape, 'loss情况')
    # print(final_loss, '损失函数值')

    return final_loss




yolo_cnn = keras.models.Sequential([
        keras.layers.Conv2D(64, 7, 2, padding='same', input_shape=[size,size,3]),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPool2D(2, 2, padding='same'),

        keras.layers.Conv2D(192, 3, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPool2D(2,2,padding='same'),

        keras.layers.Conv2D(128, 1, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(256, 3, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(256, 1, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(512, 3, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPool2D(2,2,padding='same'),


        keras.layers.Conv2D(256, 4, 2, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(512, 3, 1, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Conv2D(1024, 3, 2, padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.MaxPool2D(2, 2, padding='same'),
        # keras.layers.Conv2D(1024, 3, 1, padding='same'),
        # keras.layers.BatchNormalization(),
        # keras.layers.LeakyReLU(alpha=0.1),

        keras.layers.Flatten(),
        keras.layers.Dense(600),
        keras.layers.LeakyReLU(alpha=0.1),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(490)
        ])

n = random.randint(0, 9000)
# n = 4500
print('起始索引:', n)
total_num = n+1000
split = n
big_batch = 1000
path = 'D:\\PycharmProject\\BoundingRegression\\data\\data_labels.pkl'
with open(path, 'rb') as f:
    data = pickle.load(f)

data = data[split:total_num]

obj = DataLoader.Load(size)
data, label = obj.get_data(data, big_batch)


label = label.reshape([big_batch,7,7,1,5])
label = np.tile(label, [1,1,1,2,1])
label = label.reshape([big_batch, 490])


train_data = data.astype(np.float32)
train_label = label.astype(np.float32)


# print(train_data.shape)
# print(train_data.dtype)
# print(train_label.shape)
# print(train_label.dtype)


# yolo_cnn.summary()
# adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)
# sgd = keras.optimizers.SGD(lr=0.00005)
# yolo_cnn.compile(loss=loss_function_batch, optimizer=adam, metrics=['accuracy'])
# yolo_cnn.fit(train_data, train_label, validation_split=0.1, shuffle=True, epochs=5, batch_size=batch)

model = keras.models.load_model('yolo_model_v25.h5', custom_objects={'loss_function_batch': loss_function_batch})
# model.compile(loss=loss_function_batch, optimizer=adam, metrics=['accuracy'])
model.fit(train_data, train_label, validation_split=0.1, shuffle=True, epochs=5, batch_size=batch)

model.save('yolo_model.h5')
